{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c39adbb1",
   "metadata": {},
   "source": [
    "Q1) What is linear regression, and when would you use it?\n",
    "\n",
    "\n",
    "\n",
    "* Linear Regression is a statistical method and supervised Machine Learning algorithm in which the model finds the best fit linear line between the independent and dependent variable which finds the linear relationship between the dependent and independent variable.\n",
    "\n",
    "\n",
    "When to use linear regression :-\n",
    "\n",
    "\n",
    "* When the data have linear or sort of linear relationship.\n",
    "\n",
    "\n",
    "* When yo have to predict numerical value which is continuous in nature. Eg:- Price of something like flight fares, product costs etc, or Calculation resale value of something like mobiles,cars and bikes, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a945de71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "702add70",
   "metadata": {},
   "source": [
    "Q2) What is residual and what is residual error? \n",
    "\n",
    "\n",
    "* The difference between the actual and predicted values of the dependent variable is called residual. We can take distance of data points from best fit line to find residual.\n",
    "\n",
    "\n",
    "* The sum of squared residuals is called residual error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4c316f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12c7bc6c",
   "metadata": {},
   "source": [
    "Q3) How to find best fit line, what is best fit line and use of best fit line?\n",
    "\n",
    "\n",
    "* To find the best-fit line, an algorithm uses a method called the least squares method. It creates a line that minimizes the sum of the squared residuals.\n",
    "\n",
    "\n",
    "* It also minimize the difference between the actual values of the dependent variable and the predicted values from the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7bb808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf566558",
   "metadata": {},
   "source": [
    "Q4) What is the objective of linear regression, and how is it achieved?\n",
    "\n",
    "\n",
    "* The objective of linear regression is to build the relationship between a dependent variable and one or more independent variables using a linear equation.\n",
    "\n",
    "\n",
    "* This is achieved by finding the best fit line that minimizes the difference between the actual values and the predicted values by the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152bef69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8767ede3",
   "metadata": {},
   "source": [
    "\n",
    "Q5) What is the difference between simple and multiple linear regression?\n",
    "\n",
    "\n",
    "* Simple linear regression is a regression model with only one independent variable, while multiple linear regression is a regression model with two or more independent variables.\n",
    "\n",
    "\n",
    "* Simple linear regression is used when there is a linear relationship between the dependent variable and one independent variable, while multiple linear regression is used when there is a linear relationship between the dependent variable and two or more independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e9e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05ab2247",
   "metadata": {},
   "source": [
    "Q6) What are the assumptions of linear regression?\n",
    "\n",
    "\n",
    "We can check the assumptions on trainning data. The assumptions of linear regression are:\n",
    "\n",
    "* Linearity: The relationship between the independent and dependent variable is linear.\n",
    "\n",
    "\n",
    "* Independence: The residual should be independent of each other. It means the value of one residual should not be related to the value of another residual.\n",
    "\n",
    "\n",
    "* Homoscedasticity: Homo means same and scedastasticity means spread or scatter. It means having the same scatter. It is related to residuals. When we plot your residuals it should having  the same spread. If the spread of residuals are not same it is called Hetroscedastasticity.\n",
    "\n",
    "\n",
    "* Residual Analysis / Normality: The residual errors are normally distributed when we plot them on a graph.\n",
    "\n",
    "\n",
    "* No multicollinearity: The independent variables are not highly correlated with each other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b371ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1277f5cd",
   "metadata": {},
   "source": [
    "Q7) What is Mean Squared Error(MSE) and how to find it and what is it use?\n",
    "\n",
    "\n",
    "* MSE stands for Mean Squared Error, which measures the average squared difference between the actual and predicted values of the dependent variable in a regression model. \n",
    "\n",
    "\n",
    "How to find MSE:-\n",
    "\n",
    "\n",
    "* Calcualted the distance between all the actual and predicted data points by using euclidean distance.\n",
    "\n",
    "\n",
    "* Square all the differences and add them up.\n",
    "\n",
    "\n",
    "* Take the Mean/Average of it. This Mean is called Mean Squared Error(MSE).\n",
    "\n",
    "\n",
    "* It is a metric which use to evaluate the performance of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210bbcec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30b016d6",
   "metadata": {},
   "source": [
    "Q8) What is the difference between ordinary least squares (OLS) and logistic regression? / Difference between Linear and Logistic Regression.\n",
    "\n",
    "\n",
    "* Ordinary least squares (OLS) is a linear regression method used for numerical continuous dependent variable, while logistic regression is a regression method used for binary or categorical dependent variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25738b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "788f1c21",
   "metadata": {},
   "source": [
    "Q9) What is overfitting in linear regression?\n",
    "\n",
    "\n",
    "* Overfitting occurs when a regression model is too complex and fits the training data too well. Linear Regression Model is very sensitive to outliers.\n",
    "\n",
    "\n",
    "* If we don't deal with the outliers before making the Linear Regression Model there's a high chance of overfitting. This can lead to poor performance of model on test or new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24292ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9163892c",
   "metadata": {},
   "source": [
    "Q10) What is the difference between correlation and regression?\n",
    "\n",
    "\n",
    "* Correlation measures the strength and directional relationship between two variables, while regression build the relationship between a dependent variable and one or more independent variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1414bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0eb50acb",
   "metadata": {},
   "source": [
    "Q11) What is multicollinearity in linear regression?\n",
    "\n",
    "\n",
    "* Multicollinearity refers to a situation where two or more independent variables in a linear regression model are highly correlated with each other whether they are highly positive correlated or highly inverse correlated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3950d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65a6823b",
   "metadata": {},
   "source": [
    "Q12) What is the purpose of residual analysis in linear regression?\n",
    "\n",
    "\n",
    "* Residual analysis is used to check the assumption of linear regression like linearity, homoscedasticity, normality. \n",
    "\n",
    "\n",
    "* We can also evaluate the model by residual analysis. We make a graph of actual data points and predicted data points then analysis it to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4fc5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13d23f51",
   "metadata": {},
   "source": [
    "Q13) How do you assess the goodness of fit of a linear regression model? / How to evaulate the linear regression model?\n",
    "\n",
    "\n",
    "* We can check the goodness or evaulation of model by using various metrics such as R-squared, adjusted R-squared, Root mean square error (RMSE), Resudial analysis by ploting residuals and cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa96e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38a5f3ac",
   "metadata": {},
   "source": [
    "Q14) Whether the feature scaling is required for linear regresion or not?\n",
    "\n",
    "* Yes, feature scaling is required. We only scale the independent features not dependent feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9628c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf0ade51",
   "metadata": {},
   "source": [
    "Q15) Advantages and Disadvantages of Linear regresion model?\n",
    "\n",
    "\n",
    "Advantages:-\n",
    "\n",
    "\n",
    "* Simple and easy to understand: Linear regression is a simple and easy-to-understand method for modeling the relationship between two variables.\n",
    "\n",
    "\n",
    "* Fast computation: Linear regression can be computed quickly, even for large datasets.\n",
    "\n",
    "\n",
    "* Linear regression performs exceptionally well for linearly separable data.\n",
    "\n",
    "\n",
    "Disadvantages :- \n",
    "\n",
    "\n",
    "* Linear regression assumes that the relationship between the dependent and independent variables is linear, which may not always be the case.\n",
    "\n",
    "\n",
    "* Linear regression is sensitive to outliers in the data, which can have a large impact on the model's performance.\n",
    "\n",
    "\n",
    "* Linear regression cannot model non-linear relationships between the dependent and independent variables, which may be present in some datasets.\n",
    "\n",
    "\n",
    "* Linear regression is limited to modeling relationships between continuous dependent variables and independent variables, and cannot be used for binary or categorical dependent variables \n",
    "  without modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3936aede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce69226e",
   "metadata": {},
   "source": [
    "\n",
    "Q 16) Impact of Missing Values in Linear Regression?\n",
    "\n",
    "* It is sensitive to missing values which impact on the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f15ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecff5e2f",
   "metadata": {},
   "source": [
    "Q17) Formul of Linear Regression?\n",
    "\n",
    "Ans) y = mx+c for simple regression and y = (M1*X1)+(M2*X2)+(m3*x3)....(Mn*Xn) + c for multiple regression\n",
    "    \n",
    "     y = dependent variable\n",
    "     m = coefficient/sclope\n",
    "     x = independent variable\n",
    "     c = intercept/constant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e9c9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c58f9b9",
   "metadata": {},
   "source": [
    "Q18) what is coefficient in linear regression and what is their use?\n",
    "\n",
    "\n",
    "* Coefficient represents the slope of best fit line while describe the relationship between two variables X and Y where X is independent variable and y is dependent variable.\n",
    "\n",
    "\n",
    "* Coefficient is a numerical value which used to solve the equation of linear regression and find the value of y. The equation is y = mx+c where m is coefficient or slope. \n",
    "\n",
    "\n",
    "* When we change the value of X the value of Y will also change. Coefficient is a numerical value which tells that by what unit the value of Y will change if we change the value of X. \n",
    "\n",
    "\n",
    "* For example, in the equation y = 3x + 2, the coefficient of x is 3, which means that when x increases by 1, y will increase by 3.\n",
    "\n",
    "\n",
    "* Coefficients can be positive, negative, or zero. A positive coefficient means that it is associated with an increase in the output, while a negative coefficient means that it is associated with a decrease in the output.\n",
    "\n",
    "\n",
    "* coefficients are used in regression analysis to build the relationship between variables and to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be2bf70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39b5af09",
   "metadata": {},
   "source": [
    "Q19) What is intercept and what is their use? / What is intercept of coefficient in Linear Regression?\n",
    "\n",
    "* If the value of x is 0 then at what point it will intercept the best fit line on y axis that point is called intercept.\n",
    "\n",
    "\n",
    "* The value of intercept will remain same in regression only the value of coefficient will change.\n",
    "\n",
    "\n",
    "* Intercept is also known as Constant. We need the value of intercept to find the value of y because y = mx+c where the c is intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dbb5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da06de93",
   "metadata": {},
   "source": [
    "Q20) How to evaluate the performance of Model?\n",
    "\n",
    "\n",
    "We can evaluate the performance on Test Data.\n",
    "     \n",
    "     \n",
    "* Residual plotting :- Plot the graph of actual data points againts predictive data points, visualize it and check the goddness of fit of linear regression model.\n",
    "     \n",
    "     \n",
    "* Mean Squared Error(MSE) :- This measures the average squared difference between the predicted values and the actual values of dependent variable. The lower MSE value indicates the better performance of the model. The unit of MSE is not same as the unit of dependent vriable. The value of MSE is in square. To find the same unit as of dependet variable we need (RMSE).\n",
    "     \n",
    "     \n",
    "* Root Mean Squared Error (RMSE) :- This is similar to MSE, but the square root of the average squared difference is taken, which gives a measure of error in the same units as the dependent variable.\n",
    "     \n",
    "     \n",
    " * R-squared (R²) :- R-squared is a measure of how well the linear regression model fits the data. It ranges from 0 to 1, a higher value indicating a better fit. R-squared measures the proportion of variance in the dependent variable that can be explained by independent variables. \n",
    "    \n",
    "    \n",
    "* Adjusted R-squared: This is similar to R-squared, but adjust the number of independent variables in the model and prevent the model from overfitting. It also ranges from 0-1.\n",
    "     \n",
    "     \n",
    "* Mean Absolute Error (MAE) :- MAE is calculated by taking the absolute difference between the predicted and actual values of the dependent variable, summing them up, and then take the mean of these differences. This measures the absolute difference between the actual values and predicted values. The lower MAE value indicates the better performance of the model. The unit of MAE is same as unit of dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c11ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8861e25d",
   "metadata": {},
   "source": [
    "Q21) What is R-squared and Adjusted R-squared?\n",
    "\n",
    "\n",
    "R-Square:-\n",
    "\n",
    "\n",
    "* R-squared is known as, goodness of fit and coefficient of determination.\n",
    "\n",
    "\n",
    "* R-square is a metric by which we can evaulate the performance of our model. It measures how well the regression line fits the  data points that why it is called goodness of fit.\n",
    "\n",
    "\n",
    "* The R-square value ranges from 0-1. A high R-squared value indicates that the regression line fits the data well and our model is also perfroming well.\n",
    "\n",
    "\n",
    "* R-Square is also known as coefficient of determination because it measures the proportion of variance in the dependent variable that can be explained by one or more independent variables.\n",
    "\n",
    "\n",
    "* R-Square measures how dependent variable depends on independent variable.\n",
    "\n",
    "\n",
    "* If the value of R-square is 0.90 means 90% our dependent variable depends on independent variable and 90% of changes(variation) in the dependent variable are due to independent variables.\n",
    "\n",
    "\n",
    "* R-Square measures how much dependent variable get impacted by the independent variables.\n",
    "\n",
    "\n",
    "*  If the value of R-square is 0.90 means 90%. Our independent variables explain the dependent variable by 90%.\n",
    "\n",
    "\n",
    "* How much the difference or changes happen in dependent variable that can be explained by independent variables.\n",
    "\n",
    "\n",
    "Adjusted R-Square:-\n",
    "\n",
    "\n",
    "* It is a modified version of R-Square.\n",
    "\n",
    "\n",
    "* It adjusts the number of independent features in the model.\n",
    "\n",
    "\n",
    "* Adjusted R-Square value always less than or equal to R-Sqaue value.The value ranges from 0-1.\n",
    "\n",
    "\n",
    "Difference:- \n",
    "\n",
    "\n",
    "* R squared value assumes that all the independent variables affect the result of the model, whereas the adjusted R squared value considers only those independent variables which actually have an effect on the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100986d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b68d08fa",
   "metadata": {},
   "source": [
    "Q22) Why do need several metrics to evaluate the performance of model? Why only one metric is not enough?\n",
    "\n",
    "\n",
    "* All metrics have their several advantages and disadvantages and all metrics not perform well on all type of data. Metrics perform different on different type of datasets.\n",
    "\n",
    "\n",
    "* That's why we need all these metrics to evaluate the performance of model because any metric perform well on any particular type of data and another metric perform well on another type of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c46f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bf489b9",
   "metadata": {},
   "source": [
    "Q23) Can linear regression be used for non-linear relationships between variables?\n",
    "\n",
    "\n",
    "* Linear regression is used to build the relationship between a dependent variable and one or more independent variables.\n",
    "However, it assumes a linear relationship between the dependent variable and the independent variables.\n",
    "\n",
    "\n",
    "* If the relationship between the dependent variable and independent variable is non-linear, then linear regression may not be appropriate. In such cases, the regression line may not accurately capture the relationship between the variables, leading to poor predictions and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe218f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1b9ecc8",
   "metadata": {},
   "source": [
    "Q24) What are the impact of outliers in linear regression model?\n",
    "\n",
    "\n",
    "* Outliers in a linear regression model can have a significant impact on the model's performance and accuracy.\n",
    "\n",
    "\n",
    "* If outliers are present in the data and used to train a linear regression model, they can pull the best fit line towards them and significantly affect the slope or intercept of the line. \n",
    "\n",
    "\n",
    "* This can result in a biased model which perform good on trainning data but perform not so good on test and unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2856a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba91a2ea",
   "metadata": {},
   "source": [
    "Q25) What are the loss functions or cost functions in Linear Regression?\n",
    "\n",
    "* MAE, MSE, RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1a117c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c6f7af6",
   "metadata": {},
   "source": [
    "Q26) How to find R-Squared?\n",
    "\n",
    "\n",
    "* R-squared = 1 - (Sum of Square Residuals / Total Sum of Squares)\n",
    "\n",
    "\n",
    "* Sum of square Residuals means sum of squared differences between actual values and predicted values.\n",
    "\n",
    "\n",
    "* Total sum of square means sum of squared difference between actual values and mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d10303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3ed70b5",
   "metadata": {},
   "source": [
    "Notes :-\n",
    "\n",
    "* R2 Score or R-Squared is also known as 'Coefficient of determination', 'goodness of fit' and 'accuracy'.\n",
    "\n",
    "\n",
    "* Best fit line is also known as 'line of best fit' and 'regression line'.\n",
    "\n",
    "\n",
    "* Before putting the data into model make sure to scale data. Scale only independent features not dependent feature.\n",
    "\n",
    "\n",
    "* Linear Regression highly effected by outliers. So, dealing with outliers is must."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
