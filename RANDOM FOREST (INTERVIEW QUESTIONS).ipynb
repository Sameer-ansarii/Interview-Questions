{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0592e538",
   "metadata": {},
   "source": [
    "Q: What are the advantages of using Random Forest?\n",
    "* A: Random Forest has several advantages over other machine learning algorithms. It is highly accurate, can handle large datasets, is less prone to overfitting, and can handle missing values and categorical data.\n",
    "\n",
    "Q: How do you tune the parameters of a Random Forest model?\n",
    "* A: The main parameters that can be tuned in a Random Forest model are the number of trees, the maximum depth of the trees, and the number of features used in each split. The best values for these parameters can be found using techniques like grid search or random search.\n",
    "\n",
    "Q: What is the out-of-bag error in Random Forest?\n",
    "* A: The out-of-bag (OOB) error is the error rate of a Random Forest model on the training data that was not used to build each individual decision tree. This allows for a more accurate estimate of the generalization error of the model.\n",
    "\n",
    "Q: What is the feature importance in Random Forest?\n",
    "* A: Feature importance is a measure of how much each feature contributes to the accuracy of a Random Forest model. It is calculated by looking at the decrease in the impurity of the nodes when a particular feature is used to split the data. The higher the decrease in impurity, the more important the feature.\n",
    "\n",
    "Q: Can Random Forest be used for feature selection?\n",
    "* A: Yes, Random Forest can be used for feature selection by ranking the importance of each feature and selecting the top features. This can help to reduce the dimensionality of the data and improve the accuracy of the model.\n",
    "\n",
    "\n",
    "* What is bootstrapped aggregation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b341d88b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "677a9428",
   "metadata": {},
   "source": [
    "Q1) What is Random Forest?\n",
    "* Random Forest is an ensemble learning algorithm that builds multiple decision trees and combines the result of all decision trees to make a final prediction. \n",
    "\n",
    "\n",
    "* It is a supervised learning algorithm that can be used for both classification and regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f7546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef18e039",
   "metadata": {},
   "source": [
    "Q2) How does Random Forest work?\n",
    "* Random Forest builds multiple decision trees on random subsets of the data and combines the output of all the trees to make a final prediction. The goal is to reduce overfitting and improve the accuracy of the model.\n",
    "\n",
    "\n",
    "* It can use row sampling and feature sampling to create random subsets of data.\n",
    "\n",
    "\n",
    "* Row sampling and feature sampling means a subset of a data contains random rows and random features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7c460d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0482e9f",
   "metadata": {},
   "source": [
    "Q3)  What is the difference between Random Forest and decision trees?\n",
    "\n",
    "\n",
    "* Decision trees are a single tree-based model that predicts the outcome based on a set of rules. \n",
    "\n",
    "\n",
    "* Random Forest is an ensemble of multiple decision trees that work together to make a final prediction.\n",
    "\n",
    "\n",
    "* Random Forest is generally more accurate and less prone to overfitting than a single decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ff159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff7686be",
   "metadata": {},
   "source": [
    "Q4) How random Forest predict the outcome by multiple-decision trees?\n",
    "\n",
    "\n",
    "* In case of regresssion problem it will take the mean or average of all outputs and predict a final output.\n",
    "\n",
    "\n",
    "* In case of classification problem it will predict a outcome which is most frequent among all. Eg: out of 10 decision trees, 7 decision trees predict yes and 3 predict no. So, the final output will be yes because it is the most frequent result among all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c639b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7679051b",
   "metadata": {},
   "source": [
    "Q5) What are the advantages of using Random Forest over Decision Trees and other Machine Learning Algorithms?\n",
    "\n",
    "Random Forest has several advantages over Decision Trees and other Machine Learning Algorithms:-\n",
    "\n",
    "\n",
    "* It can be used for solve both problems, regression as well as classification.\n",
    "\n",
    "\n",
    "* It is highly accurate and can handle large datasets.\n",
    "\n",
    "\n",
    "* It is less prone to overfitting because it uses row sampling and feature sampling to create random subsets of training data and then create multiple decision of random subsets. \n",
    "\n",
    "\n",
    "* It can handle missing values by dropping the observation which contains missing values.\n",
    "\n",
    "\n",
    "* Random Forest provides a measure of feature importance, which can help to identify the most important features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4219c8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf107c72",
   "metadata": {},
   "source": [
    "### Parameters and thier use in Random Forest:-\n",
    "#### max_samples \n",
    "* Max_sample is used to set the number of samples for each random subset. \n",
    "\n",
    "\n",
    "* By default it is 'none' means all the samples will take in all random subsets but with rows replacement.\n",
    "\n",
    "\n",
    "* We can set this parameter in integer as well as in float(0-1).\n",
    "\n",
    "\n",
    "* Float means how much percentage of rows will take by each subset and int means no. of rows take by each subset.\n",
    "\n",
    "\n",
    "* max_samples = 0.9 or max_samples = 90,100,52, etc.\n",
    "\n",
    "#### max_features \n",
    "\n",
    "* By default max_features = 'auto'\n",
    "\n",
    "\n",
    "* Max_features is use to set a number of feature to create a random subset of data.\n",
    "\n",
    "\n",
    "* There are 3 options available to set this parameter which are 'auto', 'sqrt', 'log2'\n",
    "\n",
    "\n",
    "* max_features = 'auto' means it will take square root of total number of features and put features in random subset according that value. For eg: total number of columns are 10, square root of 10 is 3.16 so it will take 3 features randomly from trainning data to create a subset. But in decision tree algorithm this parameter takes all features when it set to auto.\n",
    "\n",
    "\n",
    "* max_features = 'sqrt' means it will work same as auto in random forest. \n",
    "\n",
    "\n",
    "* max_features = 'log' means it will multiple the total number of features to the value of log2 which is 0.3010 and what the values comes it will take that value to put features in random subset. Eg: total number of features are 10, 0.3010 * 10 = 3.010, So it will randomly take 3 features to create random subset.   \n",
    "\n",
    "\n",
    "* We can set this parameter in integer as well as in float(0-1).\n",
    "\n",
    "\n",
    "* Float means how much percentage of feature will take by each subset and int means no. of columns take by each subset.\n",
    "\n",
    "\n",
    "* max_features = 0.9 or max_features = 10,12,15,20, etc.\n",
    "\n",
    "#### bootstrap\n",
    "\n",
    "* Bootstrap parameter is used to define that create subset with row sampling with replacement or not.\n",
    "\n",
    "\n",
    "* By default bootstrap = True, means create subset with row sampling with replacement.\n",
    "\n",
    "\n",
    "* If bootstrap = False, means take all rows to create subset not take random rows.\n",
    "\n",
    "\n",
    "* Row sampling with replacement means some rows repeat again in same subset.\n",
    "\n",
    "\n",
    "* It will take approx 66.66% of total rows from original data to make a subset because some of the rows are repeating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834eab32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
